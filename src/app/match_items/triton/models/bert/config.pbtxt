name: "bert"                        # Имя модели (должно совпадать с именем папки)
platform: "onnxruntime_onnx"           # Платформа модели (TensorRT использует "tensorrt_plan")
max_batch_size: 8                  # Максимальный размер батча

input [
  {
    name: "input_ids"               # Имя из вашего экспорта
    data_type: TYPE_INT64           # Правильный тип для токенов
    dims: [128]                     # Максимальная длина последовательности
  },
  {
    name: "attention_mask"          # Маска внимания
    data_type: TYPE_INT64           # Тип данных
    dims: [128]                     # Та же длина последовательности
  },
  {
    name: "token_type_ids"          # Идентификаторы типов токенов
    data_type: TYPE_INT64           # Тип данных
    dims: [128]                     # Та же длина последовательности
  }
]

output [
  {
    name: "logits"                 # Имя выходного тензора
    data_type: TYPE_FP32           # Тип данных (например, FP32)
    dims: [2]                      # Размерность выходных данных (например, 1000 классов)
  }
]

dynamic_batching {                 # Настройка динамического батчинга
    preferred_batch_size: 4
    max_queue_delay_microseconds: 10000
}

instance_group [
  {
    kind: KIND_CPU                 # Использование GPU
    count: 1                       # Количество экземпляров модели на GPU
  }
]